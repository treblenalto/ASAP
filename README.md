# ASAP: AI State Analysis of Pets ğŸ¾
Analysis of Pets Using Keypoint Detection and Skeleton-Based Action Recognition.<br>
(2021.07.05~2021.08.23)

## Overview
ASAP(AI State Analysis of Pets)ëŠ” ë°˜ë ¤ë™ë¬¼ì˜ í–‰ë™ì„ ë¶„ì„í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. <br>

ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” êµ­ë‚´ì—ì„œ ì–‘ìœ¡ë˜ëŠ” ë‹¤ì–‘í•œ ê°œì˜ í’ˆì¢…ì— ëŒ€í•´ í–‰ë™ì„ ë¶„ì„í•˜ëŠ” ë²”ìš©ì ì¸ ëª¨ë¸ì„ ì œì‹œí•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ì˜ìƒ ì† ë°˜ë ¤ë™ë¬¼ì— ëŒ€í•´ 10ê°€ì§€ í–‰ë™ ë¶„ì„ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œì‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í–‰ë™ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë¨¼ì € ë°˜ë ¤ë™ë¬¼ì„ ì´¬ì˜í•œ ì˜ìƒ ì† ë°˜ë ¤ë™ë¬¼ì˜ ê´€ì ˆ í‚¤í¬ì¸íŠ¸ë¥¼ ê²€ì¶œí•œ í›„, ê´€ì ˆ í‚¤í¬ì¸íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜•ìƒí•œ ë°˜ë ¤ë™ë¬¼ì˜ ë¼ˆëŒ€ë¥¼ í†µí•´ í–‰ë™ ìœ í˜•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.<br>

ë°˜ë ¤ë™ë¬¼ì„ ë‹´ì€ ì˜ìƒì„ ì˜¬ë¦´ ì‹œ í‚¤í¬ì¸íŠ¸ ì¸ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í–‰ë™ì„ ì•Œë ¤ì¤ë‹ˆë‹¤. 

## Data
AI-Hubì—ì„œ ì œê³µí•˜ëŠ” [ë°˜ë ¤ë™ë¬¼ êµ¬ë¶„ì„ ìœ„í•œ ë™ë¬¼ ì˜ìƒ](https://aihub.or.kr/aidata/34146) ë°ì´í„° ì¤‘ ê°œ(ë°˜ë ¤ê²¬)ì˜ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.<br>

Keypoint Detection ëª¨ë¸ í•™ìŠµì‹œ ì˜ìƒ ë°ì´í„°(ì˜ìƒì˜ í”„ë ˆì„ ë³„ ì´ë¯¸ì§€)ë¥¼, Action Recognition ëª¨ë¸ í•™ìŠµì‹œ ë¼ë²¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ìœ¼ë©° ê° í•™ìŠµ ë°ì´í„°ì˜ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
* **Keypoint Detection** <br>
  | Original | Keypoint | Label |
  | :------: | :------: | :---- |
  | <img width="250" alt="data-img" src="https://user-images.githubusercontent.com/63901494/129929470-e2def238-963b-42c8-98b6-59bb0ad3b4c6.jpg"> | <img width="250" alt="data-keypoint" src="https://user-images.githubusercontent.com/63901494/129929529-235d5f39-1ec5-4452-8299-490c84702ebf.png"> | 0: ì½”<br>1: ì´ë§ˆ ì • ì¤‘ì•™<br>2: ì…ê¼¬ë¦¬(ì…ë)<br>3: ì•„ë˜ ì…ìˆ  ì¤‘ì•™<br>4: ëª©<br>5: ì•ë‹¤ë¦¬ ì˜¤ë¥¸ìª½ ì‹œì‘<br>6: ì•ë‹¤ë¦¬ ì™¼ìª½ ì‹œì‘<br>7: ì•ë‹¤ë¦¬ ì˜¤ë¥¸ìª½ ë°œëª©<br>8: ì•ë‹¤ë¦¬ ì™¼ìª½ ë°œëª©<br>9: ì˜¤ë¥¸ìª½ ëŒ€í‡´ê³¨<br>10: ì™¼ìª½ ëŒ€í‡´ê³¨<br>11: ë’·ë‹¤ë¦¬ ì˜¤ë¥¸ìª½ ë°œëª©<br>12: ë’·ë‹¤ë¦¬ ì™¼ìª½ ë§ëª©<br>13: ê¼¬ë¦¬ ì‹œì‘<br>14: ê¼¬ë¦¬ ë |

  í‚¤í¬ì¸íŠ¸ ê°ì§€ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ csv íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ê²½ë¡œì™€ í‚¤í¬ì¸íŠ¸ ì •ë³´ë¥¼ êµ¬ì„±í•´ ì£¼ì„¸ìš”. <br>
  <img width="800" alt="data-csv" src="https://user-images.githubusercontent.com/63901494/129934622-ec6e8130-50de-4893-92d6-7d040220cac9.png">

* **Action Recognition** <br>
  í–‰ë™ ë¶„ë¥˜ ëª¨ë¸ì˜ í•™ìŠµì„ ìœ„í•´ì„œëŠ” í‚¤í¬ì¸íŠ¸ ì¢Œí‘œê°’ê³¼ ê° í¬ì¸íŠ¸ì— ëŒ€í•œ confidence score, ì˜ìƒì˜ ë¼ë²¨ì¸ action class ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ json íŒŒì¼ì„ ê° ì˜ìƒì— ëŒ€í•´ êµ¬ì„±í•´ ì£¼ì„¸ìš”.
  ```
  {
    "data":[
      {"frame_index":1, "skeleton":[
        {"pose":[x.xxx, x.xxx, x.xxx, ...],   // keypoint
         "score":[x.xxx, x.xxx, x.xxx, ...]   // confidence score
        }]
      },
      {"frame_index":2, "skeleton":[
        {"pose":[x.xxx, x.xxx, x.xxx, ...],
         "score":[x.xxx, x.xxx, x.xxx, ...]
        }]
      },
      ...,]
      "label": "ê±·ê±°ë‚˜ ëœ€",
      "label_index": 5
    ...
  }
  ```
  ì˜ìƒì˜ ê° í”„ë ˆì„ë³„ ìŠ¤ì¼ˆë ˆí†¤ ì •ë³´ë¡œë¶€í„° 'ì•‰ê¸°', 'ë‘ ì•ë°œì„ ë“¤ì–´ ì˜¬ë¦¼', 'ì•ë°œ í•˜ë‚˜ë¥¼ ë“¤ì–´ ì˜¬ë¦¼', 'ëª¸ì„ í„´ë‹¤', 'ì—ë“œë¦¬ê¸°', 'ê±·ê±°ë‚˜ ëœ€', 'ê¼¬ë¦¬ë¥¼ ìœ„ë¡œ ì˜¬ë¦¬ê³  í”ë“¦', 'ë¹™ê¸€ë¹™ê¸€ ëˆë‹¤', 'ë§ˆìš´íŒ…', 'ê¼¬ë¦¬ê°€ ì•„ë˜ë¡œ í–¥í•¨' ê³¼ ê°™ì€ í–‰ë™ ë¶„ë¥˜ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. 

## Models
* [Keypoint Detection] **Keypoint RCNN** - [Mask-RCNN, 2017 (Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, Ross Girshick)](https://arxiv.org/pdf/1703.06870v3.pdf)
* [Keypoint Detection] **HRNet** - [Deep High-Resolution Representation Learning for Visual Recognition, 2019 (Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, Bin Xiao)](https://arxiv.org/pdf/1908.07919.pdf)
* [Action Recognition] **ST-GCN** - [Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition, 2018 (Sijie Yan, Yuanjun Xiong, Dahua Lin)](https://arxiv.org/pdf/1801.07455.pdf)

í•´ë‹¹ ëª¨ë¸ë“¤ì€ ëª¨ë‘ Pytorch í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ì˜€ìŠµë‹ˆë‹¤. 

<!--
**Flowchart** <br>
<img width="500" alt="tech stack" src="https://user-images.githubusercontent.com/63901494/129585982-4705c85e-c81b-4b97-87ef-20a37119d999.png"> 
-->

## Usage
í•™ìŠµì‹œ ëª¨ë¸ì˜ ìš©ëŸ‰ ë¬¸ì œë¡œ ì¸í•´ GPU í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤. <br>
Google Colabì„ í™œìš©í•  ì‹œ [ëŸ°íƒ€ì„] - [ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½] - [GPU]ë¡œ ì„¤ì •ì„ ë°”ê¿”ì£¼ì„¸ìš”.
### 1. Installation
```
git clone https://github.com/Taehee-K/ASAP.git
cd ASAP
```
### 2. Train
[Keypoint RCNN](./KeypointRCNN)
```
cd KeypointRCNN
pip install -r requirements.txt
python train.py
```
[HRNet](./HRNet)
```
cd HRNet
pip install -r requirements.txt
python train.py
```
[ST-GCN](./ST-GCN)
```
cd ST-GCN
pip install -r requirements.txt
python torchlight/setup.py install
python main.py recognition -c config/st_gcn/kinetics-skeleton/train.yaml --device 0
```
### 3. Inference
```
cd demo
pip install -r requirements.txt
python torchlight/setup.py install

// Test
python test_final.py recognition -c work_dir/stgcn_demo.yaml

// Streamlit Demo
streamlit run app.py
```

## Result
Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì„œë¹„ìŠ¤ í”„ë¡œí† íƒ€ì…ì„ ì œì‘í•˜ì˜€ìŠµë‹ˆë‹¤. <br>

<img width="600" alt="demo-streamlit" src="https://user-images.githubusercontent.com/63901494/130213347-a7735515-7440-4a09-8431-60786c1818ac.gif">

## Reference
* [pytorch/vision](https://github.com/pytorch/vision)
* [yysijie/st-gcn](https://github.com/yysijie/st-gcn)
* [leoxiaobin/deep-high-resolution-net.pytorch](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)
* [MaiHon/dacon-motion-keypoints](https://github.com/MaiHon/dacon-motion-keypoints)

## Contributors
<table>
  <tr>
    <td align="center"><a href="https://github.com/Taehee-K"><img src="https://user-images.githubusercontent.com/63901494/129619988-1a959834-313c-443c-84c2-4fc2db8ef8f6.jpg" width="100" height="100"><br /><sub><b>ê¹€íƒœí¬</b></sub></td>
    <td align="center"><a href="https://github.com/wonjae-yang"><img src="https://user-images.githubusercontent.com/63901494/129583717-42d19759-7586-4de0-aea9-5e935295f4dd.png" width="100" height="100"><br /><sub><b>ì–‘ì›ì¬</b></sub></td>
    <td align="center"><a href="https://github.com/SK-jeong"><img src="https://user-images.githubusercontent.com/63901494/129582209-1d1d194e-cf3e-48d6-b097-35a7b855a683.jpg" width="100" height="100"><br /><sub><b>ì •ì„±ê²½</b></sub></td>
    <td align="center"><a href="https://github.com/miso-choi"><img src="https://user-images.githubusercontent.com/63901494/129582741-870a71c4-6a3a-4c99-9e86-e1cd0290070a.png" width="100" height="100"><br /><sub><b>ìµœë¯¸ì†Œ</b></sub></td>
    <td align="center"><a href="https://github.com/HwangChaewon"><img src="https://user-images.githubusercontent.com/63901494/129582279-430df734-43ae-451a-991d-7bb62a170eb0.png" width="100" height="100"><br /><sub><b>í™©ì±„ì›</b></sub></td>
    <td align="center"><a href="https://github.com/HyeJung-Hwang"><img src="https://user-images.githubusercontent.com/63901494/129582233-ccf2137f-89db-4559-9bc3-be23a133e2a3.png" width="100" height="100"><br /><sub><b>í™©í˜œì •</b></sub></td>
  </tr>
</table>
